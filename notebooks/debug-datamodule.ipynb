{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import hydra\n",
    "import pyrootutils\n",
    "from pytorch_lightning.loggers import Logger\n",
    "\n",
    "\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT_ROOT\"] = \"/Users/christophe/Sites/lightning-hydra-template\"\n",
    "\n",
    "project_root = \"/Users/christophe/Sites/lightning-hydra-template\"  # Replace with your project path\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(config_path=\"../configs\", version_base=\"1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- dev\n",
      "train: true\n",
      "test: true\n",
      "save_state_dict: true\n",
      "ckpt_path: null\n",
      "seed: 42\n",
      "name: lightning-template-0.1.0\n",
      "datamodule:\n",
      "  _target_: src.datamodules.daic_datamodules.DaicDataModule\n",
      "  datasets:\n",
      "    train:\n",
      "      _target_: src.datamodules.daic_datasets.DaicDataset\n",
      "      json_path: ${paths.data_dir}/daic-woz/annotation.json\n",
      "      data_path: ${paths.data_dir}/daic-woz/raw\n",
      "      label_type: torch.FloatTensor\n",
      "    valid:\n",
      "      _target_: src.datamodules.daic_datasets.DaicDataset\n",
      "      json_path: ${paths.data_dir}/daic-woz/annotation.json\n",
      "      data_path: ${paths.data_dir}/daic-woz/raw\n",
      "      label_type: torch.FloatTensor\n",
      "    test:\n",
      "      _target_: src.datamodules.daic_datasets.DaicDataset\n",
      "      json_path: ${paths.data_dir}/daic-woz/annotation.json\n",
      "      data_path: ${paths.data_dir}/daic-woz/raw\n",
      "      label_type: torch.FloatTensor\n",
      "  loaders:\n",
      "    train:\n",
      "      batch_size: 320\n",
      "      shuffle: true\n",
      "      num_workers: 8\n",
      "      drop_last: true\n",
      "      pin_memory: true\n",
      "    valid:\n",
      "      batch_size: 320\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      drop_last: false\n",
      "      pin_memory: true\n",
      "    test:\n",
      "      batch_size: 320\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      drop_last: false\n",
      "      pin_memory: true\n",
      "    predict:\n",
      "      batch_size: 320\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      drop_last: false\n",
      "      pin_memory: true\n",
      "  transforms:\n",
      "    train:\n",
      "      order:\n",
      "      - mel_spectrogram\n",
      "      - amplitude_to_db\n",
      "      - normalize\n",
      "      mel_spectrogram:\n",
      "        _target_: torchaudio.transforms.MelSpectrogram\n",
      "        sample_rate: 22050\n",
      "        n_fft: 1024\n",
      "        hop_length: 512\n",
      "        n_mels: 64\n",
      "      amplitude_to_db:\n",
      "        _target_: torchaudio.transforms.AmplitudeToDB\n",
      "      normalize:\n",
      "        _target_: src.datamodules.components.audio_transforms.Normalize\n",
      "    valid:\n",
      "      order:\n",
      "      - mel_spectrogram\n",
      "      - amplitude_to_db\n",
      "      - normalize\n",
      "      mel_spectrogram:\n",
      "        _target_: torchaudio.transforms.MelSpectrogram\n",
      "        sample_rate: 22050\n",
      "        n_fft: 1024\n",
      "        hop_length: 512\n",
      "        n_mels: 64\n",
      "      amplitude_to_db:\n",
      "        _target_: torchaudio.transforms.AmplitudeToDB\n",
      "      normalize:\n",
      "        _target_: src.datamodules.components.audio_transforms.Normalize\n",
      "    test:\n",
      "      order:\n",
      "      - mel_spectrogram\n",
      "      - amplitude_to_db\n",
      "      - normalize\n",
      "      mel_spectrogram:\n",
      "        _target_: torchaudio.transforms.MelSpectrogram\n",
      "        sample_rate: 22050\n",
      "        n_fft: 1024\n",
      "        hop_length: 512\n",
      "        n_mels: 64\n",
      "      amplitude_to_db:\n",
      "        _target_: torchaudio.transforms.AmplitudeToDB\n",
      "      normalize:\n",
      "        _target_: src.datamodules.components.audio_transforms.Normalize\n",
      "module:\n",
      "  _target_: src.modules.single_module.MNISTLitModule\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0\n",
      "  scheduler:\n",
      "    scheduler:\n",
      "      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "      mode: max\n",
      "      factor: 0.1\n",
      "      min_lr: 1.0e-09\n",
      "      patience: 10\n",
      "    extras:\n",
      "      monitor: ${replace:\"__metric__/valid\"}\n",
      "      interval: epoch\n",
      "      frequency: 1\n",
      "  logging:\n",
      "    on_step: false\n",
      "    on_epoch: true\n",
      "    sync_dist: false\n",
      "    prog_bar: true\n",
      "  network:\n",
      "    model:\n",
      "      _target_: src.modules.models.simple_dense_net.SimpleDenseNet\n",
      "      input_size: 784\n",
      "      lin1_size: 64\n",
      "      lin2_size: 128\n",
      "      lin3_size: 64\n",
      "      output_size: 10\n",
      "    loss:\n",
      "      _target_: torch.nn.CrossEntropyLoss\n",
      "    metrics:\n",
      "      main:\n",
      "        _target_: torchmetrics.Accuracy\n",
      "        task: multiclass\n",
      "        num_classes: 10\n",
      "        top_k: 1\n",
      "      valid_best:\n",
      "        _target_: torchmetrics.MaxMetric\n",
      "    output_activation:\n",
      "      _target_: torch.softmax\n",
      "      dim: 1\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: ${replace:\"epoch{epoch:03d}-loss_valid{__loss__/valid:.4f}-metric_valid{__metric__/valid:.4f}\"}\n",
      "    monitor: ${replace:\"__metric__/valid\"}\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 5\n",
      "    mode: max\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: pytorch_lightning.callbacks.EarlyStopping\n",
      "    monitor: ${replace:\"__metric__/valid\"}\n",
      "    min_delta: 5.0e-05\n",
      "    patience: 15\n",
      "    verbose: false\n",
      "    mode: max\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  model_summary:\n",
      "    _target_: pytorch_lightning.callbacks.RichModelSummary\n",
      "    max_depth: 1\n",
      "  rich_progress_bar:\n",
      "    _target_: pytorch_lightning.callbacks.RichProgressBar\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 1\n",
      "  max_epochs: 100\n",
      "  accelerator: cpu\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  data_dir: ${paths.root_dir}/data/\n",
      "  log_dir: ${paths.root_dir}/logs/\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "  plugins: null\n",
      "  state_dict_saving_params:\n",
      "    symbols: 6\n",
      "    exceptions:\n",
      "    - loss\n",
      "  predictions_saving_params:\n",
      "    output_format: json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(config_name=\"daic_train\")\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}, 'valid': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}, 'test': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}}\n",
      "{'train': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}, 'valid': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}, 'test': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}}\n",
      "{'train': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}, 'valid': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}, 'test': {'_target_': 'src.datamodules.daic_datasets.DaicDataset', 'json_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/annotation.json', 'data_path': '/Users/christophe/Sites/lightning-hydra-template/data//daic-woz/raw', 'label_type': 'torch.FloatTensor'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.datamodules.daic_datasets.DaicDataset at 0x2a1c7d5d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.datamodule, _recursive_=False)\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup('fit')\n",
    "\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[1;32m      3\u001b[0m train_dataloader\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# inputs, labels = data[0], data[1]\u001b[39;00m\n",
      "File \u001b[0;32m~/Sites/lightning-hydra-template/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Sites/lightning-hydra-template/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1438\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[1;32m   1437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_workers()\n\u001b[0;32m-> 1438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m \n\u001b[1;32m   1442\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataloader = datamodule.train_dataloader()\n",
    "\n",
    "train_dataloader.dataset\n",
    "data = next(iter(train_dataloader))\n",
    "\n",
    "# inputs, labels = data[0], data[1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
